<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Notes on learning deep learning and everything LLM-related">
    <title>Some Keras Snippets | Learning Deep Learning</title>
    <link rel="icon" href="/favicon.png" type="image/png">
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    <style>
  body {
    background-image: radial-gradient(#8e8 1.2px, #eee 1.2px);
    background-size: 12px 12px;
  }

  main img {
    display: block;
    margin: 0 auto;
  }
</style>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-KEE68WFE95"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-KEE68WFE95');
</script>

  </head>

  <header style="text-align: center;">
    
      <a href="https://learningdeeplearning.com/">
        <img src="https://learningdeeplearning.com/images/logo.png" alt="Logo" style="max-width: 200px; height: auto; margin: 0 auto; display: block;">
      </a>
    
  </header>

  <body>
    <nav>
    <ul class="menu">
      
    </ul>
    <hr/>
    </nav>

<div class="article-meta">
<h1><span class="title">Some Keras Snippets</span></h1>

<p class="date">Sep 28, 2024</p>
</div>

<main>
<p>Here are some useful snippets that I&rsquo;ve been using pretty much every time I play with Keras.</p>
<h2 id="visualizing-the-model">Visualizing the model</h2>
<p>You can get a model summary directly in the CLI, listing its layers, shapes, and parameters:</p>
<pre tabindex="0"><code>model.summary()
</code></pre><p>Output:</p>
<pre tabindex="0"><code>┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ scale_to_0_1_range (Rescaling)  │ (None, 784)            │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ hidden_1 (Dense)                │ (None, 300)            │       235,500 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ hidden_2 (Dense)                │ (None, 100)            │        30,100 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ output (Dense)                  │ (None, 10)             │         1,010 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 266,610 (1.02 MB)
 Trainable params: 266,610 (1.02 MB)
 Non-trainable params: 0 (0.00 B)
</code></pre><p>You can also get the summary as a PNG file:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span>keras<span style="color:#f92672">.</span>plot_model(model, to_file<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;model.png&#39;</span>)
</span></span></code></pre></div><p><img src="/images/some-keras-snippets/model.png" alt=""></p>
<h2 id="setting-up-a-seed-for-reproducibility">Setting up a seed for reproducibility</h2>
<p>Since we use a pseudo-random number generator (PRNG), setting up an initial seed value ensures reproducibility. This guarantees that the same random numbers are generated in different executions of the code.</p>
<p>Random numbers are used in many parts of the training process, such as the initialization of the weights, the shuffling of the data, and the dropout layers. Setting up the same seed ensures that the results are the same every time you run the same code with the same dataset.</p>
<p>You can set by calling:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span>seed <span style="color:#f92672">=</span> <span style="color:#ae81ff">123</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>random<span style="color:#f92672">.</span>seed(seed)
</span></span><span style="display:flex;"><span>np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>seed(seed)
</span></span><span style="display:flex;"><span>tf<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>set_seed(seed)
</span></span></code></pre></div><p>Or in a much handier way, just call:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span>keras<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>set_random_seed(<span style="color:#ae81ff">123</span>)
</span></span></code></pre></div><h2 id="preventing-tensorflow-from-allocating-all-gpu-memory">Preventing TensorFlow from allocating all GPU memory</h2>
<p>By default, TensorFlow allocates the entire available GPU memory at startup. To prevent this, call the following:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span>gpus <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>config<span style="color:#f92672">.</span>experimental<span style="color:#f92672">.</span>list_physical_devices(<span style="color:#e6db74">&#39;GPU&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> gpu <span style="color:#f92672">in</span> gpus:
</span></span><span style="display:flex;"><span>  tf<span style="color:#f92672">.</span>config<span style="color:#f92672">.</span>experimental<span style="color:#f92672">.</span>set_memory_growth(gpu, <span style="color:#66d9ef">True</span>)
</span></span></code></pre></div><h2 id="checking-vram-usage">Checking VRAM usage</h2>
<p>To check the amount of VRAM used by TensorFlow on the spot, call:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span>tf<span style="color:#f92672">.</span>config<span style="color:#f92672">.</span>experimental<span style="color:#f92672">.</span>get_memory_info(<span style="color:#e6db74">&#39;GPU:0&#39;</span>)
</span></span></code></pre></div><p>Replace <code>GPU:0</code> with the desired GPU identifier.</p>
<h2 id="setting-up-a-custom-callback">Setting up a custom callback</h2>
<p>You can create a custom callback by subclassing the <code>Callback</code> class from <code>keras.callbacks</code>. Below are all the methods that can be overridden (override only the ones you need):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">CustomCallback</span>(keras<span style="color:#f92672">.</span>callbacks<span style="color:#f92672">.</span>Callback):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">on_train_begin</span>(self, logs<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">pass</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">on_train_end</span>(self, logs<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">pass</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">on_epoch_begin</span>(self, epoch, logs<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">pass</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">on_epoch_end</span>(self, epoch, logs<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">pass</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">on_test_begin</span>(self, logs<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">pass</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">on_test_end</span>(self, logs<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">pass</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">on_predict_begin</span>(self, logs<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">pass</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">on_predict_end</span>(self, logs<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">pass</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">on_train_batch_begin</span>(self, batch, logs<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">pass</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">on_train_batch_end</span>(self, batch, logs<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">pass</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">on_test_batch_begin</span>(self, batch, logs<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">pass</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">on_test_batch_end</span>(self, batch, logs<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">pass</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">on_predict_batch_begin</span>(self, batch, logs<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">pass</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">on_predict_batch_end</span>(self, batch, logs<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">pass</span>
</span></span></code></pre></div><h2 id="shut-up-tensorflow">Shut up TensorFlow</h2>
<p>When importing TensorFlow, it often generates excessive log messages:</p>
<pre tabindex="0"><code>2024-09-15 12:58:03.328316: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-09-15 12:58:03.340620: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-09-15 12:58:03.344415: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-09-15 12:58:03.354197: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-09-15 12:58:03.955991: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
x_train shape: (60000, 28, 28, 1)
60000 train samples
10000 test samples
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1726415884.584769	6242 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1726415884.621959	6242 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1726415884.623432	6242 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1726415884.625631	6242 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1726415884.627330	6242 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1726415884.629009	6242 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1726415884.777146	6242 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1726415884.778641	6242 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1726415884.780130	6242 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-09-15 12:58:04.781466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3984 MB memory:  -&gt; device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:10:00.0, compute capability: 7.5
</code></pre><p>To suppress these logs, set the following environment variable (in your <code>.bashrc</code> file):</p>
<pre tabindex="0"><code>export TF_CPP_MIN_LOG_LEVEL=3
</code></pre><p>And for the &ldquo;NUMA node&rdquo; message, set up the following to run at system start:</p>
<pre tabindex="0"><code>echo 0 &gt; /sys/bus/pci/devices/0000:10:00.0/numa_node
</code></pre><p>The <code>0000:10:00.0</code> identifier was taken by checking <code>lspci -D | grep NVIDIA</code> (check the one saying &ldquo;VGA compatible controller&rdquo;).</p>
<h2 id="sources">Sources</h2>
<ul>
<li><a href="https://keras.io/api/models/model/#summary-method"><code>summary</code> method</a></li>
<li><a href="https://keras.io/api/utils/model_plotting_utils/">Model plotting utilities</a></li>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/set_random_seed"> tf.keras.utils.set_random_seed</a></li>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/config/experimental/set_memory_growth">tf.config.experimental.set_memory_growth</a></li>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/config/experimental/get_memory_info">tf.config.experimental.get_memory_info</a></li>
<li><a href="https://keras.io/guides/writing_your_own_callbacks/">Writing your own callbacks</a></li>
<li><a href="https://github.com/tensorflow/tensorflow/blob/043c4d515f352eff052b42dfc5a4bf5fe0dc00f6/tensorflow/c/logging.h#L27-L32">TF_LogLevel</a></li>
<li><a href="https://askubuntu.com/q/1379119/153234">How to set the NUMA node for an (NVIDIA) GPU persistently? - Ask Ubuntu</a></li>
</ul>

</main>

    <hr>
    <footer>
      <p>
        <a href="mailto:talleslasmar@gmail.com">📧</a>
        | 
        <a href="https://github.com/tallesl"><img src="https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png" alt="GitHub" style="height: 25px; vertical-align: middle;"></a>
        |
        <a href="https://creativecommons.org/publicdomain/zero/1.0/"><img src="https://licensebuttons.net/p/zero/1.0/88x31.png" alt="CC0" style="height: 20px; vertical-align: middle;"></a>
      </p>
    </footer>
  </body>
</html>

