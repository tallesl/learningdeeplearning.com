<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Notes on learning deep learning and everything LLM-related">
    <title>Profiling CUDA Calls | Learning Deep Learning</title>
    <link rel="icon" href="/favicon.png" type="image/png">
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    <style>
  body {
    background-image: radial-gradient(#8e8 1.2px, #eee 1.2px);
    background-size: 12px 12px;
  }

  main img {
    display: block;
    margin: 0 auto;
  }
</style>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-KEE68WFE95"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-KEE68WFE95');
</script>

  </head>

  <header style="text-align: center;">
    
      <a href="https://learningdeeplearning.com/">
        <img src="https://learningdeeplearning.com/images/logo.png" alt="Logo" style="max-width: 200px; height: auto; margin: 0 auto; display: block;">
      </a>
    
  </header>

  <body>
    <nav>
    <ul class="menu">
      
    </ul>
    <hr/>
    </nav>

<div class="article-meta">
<h1><span class="title">Profiling CUDA Calls</span></h1>

<p class="date">Sep 11, 2024</p>
</div>

<main>
<p>Profiling the CUDA calls that occur behind the scenes can help evaluate different approaches and identify performance
bottlenecks in GPU-accelerated applications. The <strong>NVIDIA Visual Profiler</strong> is an easy-to-use tool that enables you to
visualize the execution of CUDA kernels and API calls, providing valuable insights for optimizing your code and
improving GPU efficiency.</p>
<h2 id="running-a-sample-cuda-code">Running a sample CUDA code</h2>
<p>First, let&rsquo;s write a basic CUDA program:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;stdio.h&gt;</span><span style="color:#75715e">
</span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;cuda_runtime.h&gt;</span><span style="color:#75715e">
</span><span style="color:#75715e"></span>
__global__ <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">add</span>(<span style="color:#66d9ef">int</span> a, <span style="color:#66d9ef">int</span> b, <span style="color:#66d9ef">int</span> <span style="color:#f92672">*</span>c)
{
    <span style="color:#f92672">*</span>c <span style="color:#f92672">=</span> a <span style="color:#f92672">+</span> b;
}

<span style="color:#66d9ef">int</span> <span style="color:#a6e22e">main</span>()
{
    <span style="color:#66d9ef">int</span> a <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>, b <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>, c;
    <span style="color:#66d9ef">int</span> <span style="color:#f92672">*</span>dev_c;

    cudaMalloc(<span style="color:#f92672">&amp;</span>dev_c, <span style="color:#66d9ef">sizeof</span>(<span style="color:#66d9ef">int</span>));

    add<span style="color:#f92672">&lt;&lt;&lt;</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span><span style="color:#f92672">&gt;&gt;&gt;</span>(a, b, dev_c);
    cudaMemcpy(<span style="color:#f92672">&amp;</span>c, dev_c, <span style="color:#66d9ef">sizeof</span>(<span style="color:#66d9ef">int</span>), cudaMemcpyDeviceToHost);
    printf(<span style="color:#e6db74">&#34;%d + %d is %d</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, a, b, c);

    cudaFree(dev_c);

    <span style="color:#66d9ef">return</span> <span style="color:#ae81ff">0</span>;
}
</code></pre></div><p>Compiling it:</p>
<pre tabindex="0"><code>$ nvcc sample.cu -o sample
</code></pre><h2 id="profiling-calls-with-nvprof">Profiling calls with nvprof</h2>
<p>We can track the GPU activity of our small test program by simply running it with <code>nvprof</code>:</p>
<pre tabindex="0"><code>$ nvprof ./sample
==72071== NVPROF is profiling process 72071, command: ./sample
1 + 2 is 3
==72071== Profiling application: ./sample
==72071== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
 GPU activities:   56.32%  3.4240us         1  3.4240us  3.4240us  3.4240us  add(int, int, int*)
                   43.68%  2.6560us         1  2.6560us  2.6560us  2.6560us  [CUDA memcpy DtoH]
      API calls:   99.08%  165.86ms         1  165.86ms  165.86ms  165.86ms  cudaMalloc
                    0.82%  1.3800ms       101  13.663us      80ns  732.85us  cuDeviceGetAttribute
                    0.05%  81.893us         1  81.893us  81.893us  81.893us  cudaFree
                    0.02%  38.522us         1  38.522us  38.522us  38.522us  cudaMemcpy
                    0.01%  20.007us         1  20.007us  20.007us  20.007us  cudaLaunchKernel
                    0.01%  9.0370us         1  9.0370us  9.0370us  9.0370us  cuDeviceGetName
                    0.00%  6.5120us         1  6.5120us  6.5120us  6.5120us  cuDeviceGetPCIBusId
                    0.00%  1.4030us         3     467ns     281ns     831ns  cuDeviceGetCount
                    0.00%     572ns         2     286ns     121ns     451ns  cuDeviceGet
                    0.00%     220ns         1     220ns     220ns     220ns  cuDeviceTotalMem
                    0.00%     160ns         1     160ns     160ns     160ns  cuDeviceGetUuid
</code></pre><p>Here we can see the performed calls directly on stdout. Let&rsquo;s do it again, but with a GUI now:</p>
<pre tabindex="0"><code>$ nvprof -o sample.nvvp ./sample
==74063== NVPROF is profiling process 74063, command: ./sample
1 + 2 is 3
==74063== Generated result file: sample.nvvp
$ nvvp sample.nvvp
</code></pre><p><img src="/images/profiling-cuda-calls/nvvp-1.png" alt=""></p>
<p>The 99% of time spent by <code>cudaMalloc</code> pops out immediatelly when inspecting the profiling visually.</p>
<h2 id="pytorch">PyTorch</h2>
<p>Out of curiosity, let&rsquo;s check the profiling on a <a href="https://github.com/pytorch/examples/blob/37a1866/mnist/main.py">PyTorch MNIST example</a>:</p>
<p><img src="/images/profiling-cuda-calls/nvvp-2.png" alt=""></p>
<p>It&rsquo;s interesting to observe the symmetry of operations on both the left and right sides. Each begins with a couple of
&lsquo;host to device&rsquo; memory copies, which I believe correspond to the digit image and its label, respectively.</p>

</main>

    <hr>
    <footer>
      <p>
        <a href="mailto:talleslasmar@gmail.com">ðŸ“§</a>
        | 
        <a href="https://github.com/tallesl"><img src="https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png" alt="GitHub" style="height: 25px; vertical-align: middle;"></a>
        |
        <a href="https://creativecommons.org/publicdomain/zero/1.0/"><img src="https://licensebuttons.net/p/zero/1.0/88x31.png" alt="CC0" style="height: 20px; vertical-align: middle;"></a>
      </p>
    </footer>
  </body>
</html>

